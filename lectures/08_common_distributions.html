

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>7. Common Probability Distributions &#8212; Lecture Notes on Fundamentals of Data Analysis</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/08_common_distributions';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Basic Elements of Information Theory" href="09_information_theory.html" />
    <link rel="prev" title="6. Probability for Data Manipulation" href="07_probability.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Lecture Notes on Fundamentals of Data Analysis - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Lecture Notes on Fundamentals of Data Analysis - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Lecture Notes on Fundamental of Data Analysis
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Theory</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_intro_data_analysis.html">1. Introduction to Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_main_data_analysis_concepts.html">2. Main data analysis concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_misure_di_frequenze_e_rappresentazione_grafica_dei_dati.html">3. Misure di Frequenze e Rappresentazione Grafica dei Dati</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_misure_di_tendenza_centrale_dispersione_e_forma.html">4. Misure di Tendenza Centrale, Dispersione e Forma</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_associazione_variabili.html">5. Associazione tra Variabili</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_probability.html">6. Probability for Data Manipulation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Common Probability Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_information_theory.html">8. Basic Elements of Information Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_statistical_inference.html">9. Statistical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_linear_regression.html">10. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_logistic_regression.html">11. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_causal_analysis.html">12. Causal Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_data_as_nd_points.html">13. Data as N-Dimensional Points</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_clustering.html">14. Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_density_estimation.html">15. Density Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_principal_component_analysis.html">16. Principal Component Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_predictive_modeling.html">17. Introduction to Predictive Modelling and Regression Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="19_classification.html">18. Classification Task and Evaluation Measures</a></li>
<li class="toctree-l1"><a class="reference internal" href="20_discriminative_models_for_classification.html">19. Discriminative Models for Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="21_generative_models_for_classification.html">20. Generative Models for Classification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Laboratories</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../laboratories/01_setup.html">21. Introduzione ai laboratori e Installazione dell’Ambiente di Lavoro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/02_intro_python.html">22. Introduzione a Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/03_intro_numpy.html">23. Introduzione a Numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/04_intro_matplotlib.html">24. Introduzione a Matplotlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/05_intro_pandas.html">25. Introduzione a Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/06_misure_di_frequenze_e_rappresentazioni_grafiche_dei_dati.html">26. Laboratorio su Misure di Frequenze e Rappresentazione Grafica dei Dati</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/07_misure_di_tendenza_centrale_dispersione_e_forma.html">27. Laboratorio su Misure di Tendenza Centrale, Dispersione e Forma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/08_associazione_variabili.html">28. Associazione tra Variabili</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/09_heart-disease-analysis.html">29. Exploratory Analysis on the Heart Disease Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/10_statistical_inference.html">30. Laboratory on Statistical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/11_regressione_lineare.html">31. Laboratorio su Regressione Lineare</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/12_regressione_logistica.html">32. Laboratorio su regressione logistica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/13_linear_logistic_regression_example_analysis.html">33. Linear and Logistic Regression Laboratory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/14_clustering_density_estimation_pca.html">34. Clustering, Density Estimation, and Principal Component Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../laboratories/15_customer_segmentation_analysis.html">35. Customer Segmentation Analysis Example</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/antoninofurnari/fadlecturenotes/blob/master/lecturenotes/lectures/08_common_distributions.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/antoninofurnari/fadlecturenotes" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/antoninofurnari/fadlecturenotes/issues/new?title=Issue%20on%20page%20%2Flectures/08_common_distributions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/08_common_distributions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Common Probability Distributions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-uniform-distribution">7.1. Discrete Uniform Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">7.1.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bernoulli-distribution">7.2. Bernoulli Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.2.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binomial-distribution">7.3. Binomial Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">7.3.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-distribution">7.4. Poisson Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.4.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-distribution">7.5. Categorical Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-distribution">7.5.1. Multinomial Distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-distribution">7.6. Gaussian Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">7.6.1. Interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian">7.6.2. Multivariate Gaussian</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-sigma">7.6.2.1. Effect of <span class="math notranslate nohighlight">\(\Sigma\)</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-parameters-of-a-gaussian-distribution">7.6.3. Estimation of the Parameters of a Gaussian Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">7.6.4. Central Limit Theorem</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-distribution">7.7. Laplacian Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">7.8. References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="common-probability-distributions">
<h1><span class="section-number">7. </span>Common Probability Distributions<a class="headerlink" href="#common-probability-distributions" title="Permalink to this heading">#</a></h1>
<p>There are several common probability distributions which can be used to
describe random events. <strong>These distributions have an analytical
formulation which depends generally on one or more parameters.</strong></p>
<p>When we have <strong>enough evidence that a given random variable is well
described by one of these distributions</strong>, we can simply “fit” the
distribution to the data (i.e., choose the correct parameters for the
distribution) and use the analytical formulation to deal with the random
variable.</p>
<p>It is hence useful to know the <strong>most common probability distributions</strong>
so that we can recognize the cases in which they can be used.</p>
<section id="discrete-uniform-distribution">
<h2><span class="section-number">7.1. </span>Discrete Uniform Distribution<a class="headerlink" href="#discrete-uniform-distribution" title="Permalink to this heading">#</a></h2>
<p>The discrete uniform distribution is controlled by a parameter <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span> and assumes that all outcomes have the same probability of occurring:</p>
<div class="math notranslate nohighlight">
\[P(X=a_i) = \frac{1}{k}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\Omega = \{a_1,\ldots,a_k\}\)</span>.</p>
<p>It can be shown that:</p>
<div class="math notranslate nohighlight">
\[E[X] = \frac{k+1}{2}\]</div>
<div class="math notranslate nohighlight">
\[Var[X] = \frac{1}{12}(k^2-1)\]</div>
<section id="example">
<h3><span class="section-number">7.1.1. </span>Example<a class="headerlink" href="#example" title="Permalink to this heading">#</a></h3>
<p>The outcomes of rolling a fair die follow a uniform distribution with <span class="math notranslate nohighlight">\(k=6\)</span>, as shown in the diagram below:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/689d5dc078fb3b115fe23860123251ca54e9328aa880529a13032e78754d263a.png" src="../_images/689d5dc078fb3b115fe23860123251ca54e9328aa880529a13032e78754d263a.png" />
</div>
</div>
</section>
</section>
<section id="bernoulli-distribution">
<h2><span class="section-number">7.2. </span>Bernoulli Distribution<a class="headerlink" href="#bernoulli-distribution" title="Permalink to this heading">#</a></h2>
<p>The Bernoulli distribution is a distribution over a single binary random
variable, i.e., the variable <span class="math notranslate nohighlight">\(X\)</span> can take only two values:
<span class="math notranslate nohighlight">\(\left\{ 0,1 \right\}\)</span>.</p>
<p>The distribution is controlled by a single parameter
<span class="math notranslate nohighlight">\(\phi \in \lbrack 0,1\rbrack\)</span>, which gives the probability of the
variable to be equal to 1.</p>
<p>The analytical formulation of the Bernoulli distribution is very simple:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X = 1) = \phi\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X = 0) = 1 - \phi\)</span></p></li>
</ul>
<p>The expected value and variance of the associated random variable are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E\lbrack x\rbrack = \phi\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(Var(x) = \phi(1 - \phi)\)</span>.</p></li>
</ul>
<section id="id1">
<h3><span class="section-number">7.2.1. </span>Example<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>A skewed coin lands on “head” <span class="math notranslate nohighlight">\(60\%\)</span> of the
times. If we define <span class="math notranslate nohighlight">\(X = 1\)</span> when the outcome is head and <span class="math notranslate nohighlight">\(X = 0\)</span> when
the outcome is tail, then the variable follows a Bernoulli distribution
with <span class="math notranslate nohighlight">\(\phi = 0.6\)</span>.</p>
</section>
</section>
<section id="binomial-distribution">
<h2><span class="section-number">7.3. </span>Binomial Distribution<a class="headerlink" href="#binomial-distribution" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/b4ba486ffca81fed577fcc5d0d825a6576c5dcd4433a1eed434d02c99df6b8aa.png" src="../_images/b4ba486ffca81fed577fcc5d0d825a6576c5dcd4433a1eed434d02c99df6b8aa.png" />
</div>
</div>
<p>The binomial distribution is a discrete probability distribution (PMF)
over natural numbers with parameters <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\(\mathbf{p}\)</span></p>
<p>It models <strong>the probability of obtaining</strong> <span class="math notranslate nohighlight">\(\mathbf{k}\)</span> <strong>successes in a
sequence of</strong> <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> <strong>independent experiments which follow a
Bernoulli distribution with parameter</strong>
<span class="math notranslate nohighlight">\(\mathbf{p}\mathbf{\ (}\mathbf{\phi}\mathbf{=}\mathbf{p}\mathbf{)}\)</span><strong>;</strong></p>
<p>The probability mass function of the distribution is given by:</p>
<div class="math notranslate nohighlight">
\[P(k) = \binom{n}{k}p^{k}(1 - p)^{n - k}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k\)</span> is the number of successes</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> is the number of independent trials</p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span> is the probability of a success in a single trial</p></li>
</ul>
<p>The expected value is <span class="math notranslate nohighlight">\(E\lbrack k\rbrack = np\)</span>;</p>
<p>The variance is <span class="math notranslate nohighlight">\(Var\lbrack k\rbrack = np(1 - p)\)</span>;</p>
<section id="id2">
<h3><span class="section-number">7.3.1. </span>Example<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>What is the probability of tossing a coin three times and obtaining
three heads? We have:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k = 3\)</span>: number of successes (three times head)</p></li>
<li><p><span class="math notranslate nohighlight">\(n = 3\)</span>: number of trials</p></li>
<li><p><span class="math notranslate nohighlight">\(p = 0.5\)</span>: the probability of getting a head when tossing a coin</p></li>
</ul>
<p>The required probability will be given by:</p>
<div class="math notranslate nohighlight">
\[P(3) = \binom{3}{3}{0.5}^{3}(1 - 0.5)^{3 - 3} = {0.5}^{3} = 0.125\]</div>
<p><strong>Exercise</strong></p>
<p>What is the probability of tossing an unfair coin
(<span class="math notranslate nohighlight">\(P\left( 'head^{'} \right) = 0.6\)</span>) 7 times and obtaining <span class="math notranslate nohighlight">\(2\)</span> tails?</p>
</section>
</section>
<section id="poisson-distribution">
<h2><span class="section-number">7.4. </span>Poisson Distribution<a class="headerlink" href="#poisson-distribution" title="Permalink to this heading">#</a></h2>
<p>The Poisson distribution expresses the <strong>probability of a given number of events occurring in a fixed interval of time or space if they occur independently with a known rate</strong>. It is useful to model situations in which the number of events is very large and the probability of a given event happening is relatively small. The Poisson distribution is controlled by a parameter <span class="math notranslate nohighlight">\(\lambda&gt;0\)</span> (the rate at which each event occurs) and defined as:</p>
<div class="math notranslate nohighlight">
\[P(X=x) = \frac{\lambda^x}{x!}\exp(-\lambda)\]</div>
<p>with <span class="math notranslate nohighlight">\(x=0,1,2,3,\ldots\)</span> representing the number of events happening at the same time/space. The plot below shows the Poisson distribution for different choices of the <span class="math notranslate nohighlight">\(\lambda\)</span> parameter:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/26b32f3ff10869b84d807ff3b8402495ab558285601402006112a858df2434d1.png" src="../_images/26b32f3ff10869b84d807ff3b8402495ab558285601402006112a858df2434d1.png" />
</div>
</div>
<section id="id3">
<h3><span class="section-number">7.4.1. </span>Example<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>During World War II Germans bombed the south of London many times. People started to believe that some areas were more targeted by the bombing and hence started moving from one part of a city to another in an attempt to avoid those areas.</p>
<p>After the end of the war, R. D. Charles showed that the bombings were actually random and independent. To do so, he divided the interested area in <span class="math notranslate nohighlight">\(576\)</span> squares of <span class="math notranslate nohighlight">\(0.24 Km^2\)</span>. The number of total bombs was <span class="math notranslate nohighlight">\(537\)</span>, hence less than one per square (a rare event). Assuming that the bombing was uniform and casual, the probability of a square being bombed would be:</p>
<div class="math notranslate nohighlight">
\[\lambda = \frac{537}{576}\]</div>
<p>We can hence compute the expected probability that <span class="math notranslate nohighlight">\(x\)</span> squares were bombed as <span class="math notranslate nohighlight">\(P(X=x)\)</span>, where <span class="math notranslate nohighlight">\(P\)</span> is a Poisson function with <span class="math notranslate nohighlight">\(\lambda=\frac{537}{576}\)</span>. The expected number of areas being bombed <span class="math notranslate nohighlight">\(x\)</span> times will be: <span class="math notranslate nohighlight">\(P(X=x)\times576\)</span></p>
<p>Comparing the expected numbers with the measured ones, we obtain the following table:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Expected</th>
      <th>Real</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>226.742723</td>
      <td>229</td>
    </tr>
    <tr>
      <th>1</th>
      <td>211.390351</td>
      <td>211</td>
    </tr>
    <tr>
      <th>2</th>
      <td>98.538731</td>
      <td>93</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30.622279</td>
      <td>35</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.137224</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Since the numbers are very close, we can imagine that the bombing was really random.</p>
</section>
</section>
<section id="categorical-distribution">
<h2><span class="section-number">7.5. </span>Categorical Distribution<a class="headerlink" href="#categorical-distribution" title="Permalink to this heading">#</a></h2>
<p>The <strong>multinoulli</strong> or <strong>categorical</strong> distribution is a distribution of
a <em>single discrete variable with</em> <span class="math notranslate nohighlight">\(k\)</span> <em>different states</em>, where <span class="math notranslate nohighlight">\(k\)</span> is
finite.</p>
<ul class="simple">
<li><p>The distribution is parametrized by a vector
<span class="math notranslate nohighlight">\(\mathbf{p} \in \lbrack 0,1\rbrack^k\)</span>, where <span class="math notranslate nohighlight">\(p_{i}\)</span> gives the
probability of the i^th^ state.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> must be such that <span class="math notranslate nohighlight">\(\sum_{i = 1}^kp_{i} = 1\)</span> to
obtain a valid probability distribution.</p></li>
<li><p>The analytical form of the distribution is given by:
<span class="math notranslate nohighlight">\(p(x = i) = p_{i}\)</span>;</p></li>
</ul>
<p>This distribution is the <strong>generalization of the Bernoulli distribution
to the case of multiple states</strong>.</p>
<p><strong>Example:</strong></p>
<p>Rolling a fair die. In this case, <span class="math notranslate nohighlight">\(k = 6\)</span> and
<span class="math notranslate nohighlight">\(p_{i} = \frac{1}{k}\ ,\ i = 0,\ldots,k \ \)</span>.</p>
<section id="multinomial-distribution">
<h3><span class="section-number">7.5.1. </span>Multinomial Distribution<a class="headerlink" href="#multinomial-distribution" title="Permalink to this heading">#</a></h3>
<p>The multinomial distribution <strong>generalizes the binomial distribution to
the case in which the experiments are not binary</strong>, but they can have
multiple outcomes (e.g., <em>a dice vs a coin</em>).</p>
<p>In particular, the multinomial distribution models the probability of
obtaining exactly <span class="math notranslate nohighlight">\((n_{1},\ldots,n_{k})\)</span> occurrences (with
<span class="math notranslate nohighlight">\(n = \sum_{i}^{}n_{i}\)</span>) for each of the <span class="math notranslate nohighlight">\(k\)</span> possible outcomes in a
sequence of <span class="math notranslate nohighlight">\(n\)</span> independent experiments which follow a Categorial
distribution with probabilities <span class="math notranslate nohighlight">\(p_{1},\ldots,p_{k}\)</span>.</p>
<p>The parameters of the distribution are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span>: the number of trials</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span>: the number of possible outcomes</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{1},\ldots,p_{k}\)</span> the probabilities of obtaining a given class in
each trial (with <span class="math notranslate nohighlight">\(\sum_{i = 1}^{k}p_{i} = 1\)</span>)</p></li>
</ul>
<p>The PMF of the distribution is:</p>
<div class="math notranslate nohighlight">
\[P\left( n_{1},\ldots,n_{k} \right) = \frac{n!}{n_{1}!\ldots n_{k}!}p_{1}^{n_{1}} \cdot \ldots \cdot p_{k}^{n_{k}}\]</div>
<p>The mean is: <span class="math notranslate nohighlight">\(E\left\lbrack n_{i} \right\rbrack = np_{i}\)</span>.</p>
<p>The variance is:
<span class="math notranslate nohighlight">\(Var\left\lbrack n_{i} \right\rbrack = np_{i}(1 - p_{i})\)</span>.</p>
<p>The covariance between two of the input variables is:
<span class="math notranslate nohighlight">\(Cov\left( n_{i},n_{j} \right) = - np_{i}p_{j}\ (i \neq j)\)</span>.</p>
<p><strong>Example</strong></p>
<p>Given a fair die with 6 possible outcomes, what is the probability of
getting 3 times 1, 2 times 2, 4 time 3, 5 times 4, 0 times 5, and 1 time
6, rolling the dice for 15 times?</p>
<p>We have:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n = 15\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(k = 6\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p_{1} = p_{2} = \ldots p_{6} = \frac{1}{6}\)</span></p></li>
</ul>
<p>The required probability is given by:</p>
<div class="math notranslate nohighlight">
\[P(3,2,4,5,0,1) = \frac{15!}{3!2!4!5!0!1!} \cdot \frac{1}{6^{3}} \cdot \frac{1}{6^{2}} \cdot \frac{1}{6^{4}} \cdot \frac{1}{6^{5}} \cdot \frac{1}{6^{0}} \cdot \frac{1}{6^{1}} = 8.04 \cdot 10^{- 5}\]</div>
</section>
</section>
<section id="gaussian-distribution">
<h2><span class="section-number">7.6. </span>Gaussian Distribution<a class="headerlink" href="#gaussian-distribution" title="Permalink to this heading">#</a></h2>
<p>The Bernoulli and Categorical distributions are PMF, i.e., distributions
over discrete random variables.</p>
<p>A common PDF when dealing with real values is the <strong>Gaussian
distribution,</strong> also known as <strong>Normal Distribution</strong>.</p>
<p>The distribution is characterized by two parameters:</p>
<ul class="simple">
<li><p>The mean <span class="math notranslate nohighlight">\(\mu\mathfrak{\in R}\)</span></p></li>
<li><p>The standard deviation <span class="math notranslate nohighlight">\(\sigma \in (0, + \infty)\)</span></p></li>
</ul>
<p>In practice, the distribution is often <em>seen in terms of</em> <span class="math notranslate nohighlight">\(\mu\)</span> <em>and</em>
<span class="math notranslate nohighlight">\(\sigma^{2}\)</span> rather than <span class="math notranslate nohighlight">\(\sigma\)</span>, where <span class="math notranslate nohighlight">\(\sigma^{2}\)</span> is called <strong>the
variance</strong>.</p>
<p>The analytical formulation of the Normal distribution is as follows:</p>
<div class="math notranslate nohighlight">
\[N\left( x;\mu,\sigma^{2} \right) = \sqrt{\frac{1}{2\pi\sigma^{2}}}e^{- \frac{1}{2\sigma^{2}}(x - \mu)^{2}}\]</div>
<p>The term under the square root is a normalization term which ensures
that the distribution integrates to 1.</p>
<p>The expectation and variance of a variable following the Normal
distribution are as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E\lbrack x\rbrack = \mu\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Var\lbrack x\rbrack = \sigma^{2}\)</span></p></li>
</ul>
<p>The Gaussian distribution is very used when we do not have much prior
knowledge on the real distribution we wish to model. This in mainly due
to the <strong>central limit theorem</strong>, which states that the sum of many
independent random variables with the same distribution is approximately
normally distributed.</p>
<section id="interpretation">
<h3><span class="section-number">7.6.1. </span>Interpretation<a class="headerlink" href="#interpretation" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/ff3fc200b1dac4e599d0357ac8790cdeb0b07329a61bda14eceb69124445e94e.png" src="../_images/ff3fc200b1dac4e599d0357ac8790cdeb0b07329a61bda14eceb69124445e94e.png" />
</div>
</div>
<p>If we plot the PDF of a Normal distribution, we can find that it is easy
to interpret the meaning of its parameters:</p>
<ul class="simple">
<li><p>The resulting curve has a maximum (highest probability) when
<span class="math notranslate nohighlight">\(x = \mu\)</span></p></li>
<li><p>The curve is symmetric, with the inflection points at
<span class="math notranslate nohighlight">\(x = \mu \pm \sigma\)</span></p></li>
<li><p>The example shows a normal distribution for <span class="math notranslate nohighlight">\(\mu = 0\)</span> and
<span class="math notranslate nohighlight">\(\sigma = 1\)</span></p></li>
</ul>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/f881bd32ce8ea398c660d4f1b689083eceb9caa2865df155d8674291b720b160.png" src="../_images/f881bd32ce8ea398c660d4f1b689083eceb9caa2865df155d8674291b720b160.png" />
</div>
</div>
<p>Another notable property of the Normal distribution is that:</p>
<ul class="simple">
<li><p>About <span class="math notranslate nohighlight">\(68\%\)</span> of the density is comprised in the interval
<span class="math notranslate nohighlight">\(\lbrack - \sigma,\sigma\rbrack\)</span>;</p></li>
<li><p>About <span class="math notranslate nohighlight">\(95\%\)</span> of the density is comprised in the interval
<span class="math notranslate nohighlight">\(\lbrack - 2\sigma,2\sigma\rbrack\)</span>;</p></li>
<li><p>Almost 100% of the density is comprised in the interval
<span class="math notranslate nohighlight">\(\lbrack - 3\sigma,3\sigma\rbrack\)</span>.</p></li>
</ul>
</section>
<section id="multivariate-gaussian">
<h3><span class="section-number">7.6.2. </span>Multivariate Gaussian<a class="headerlink" href="#multivariate-gaussian" title="Permalink to this heading">#</a></h3>
<p>The formulation of the Gaussian distribution generalizes to the
multivariate case, i.e., the case in which <span class="math notranslate nohighlight">\(X\)</span> is n-dimensional.</p>
<p>In that case, the distribution is parametrized by a <strong>n-dimensional
vector</strong> <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> and a
<span class="math notranslate nohighlight">\(\mathbf{n}\mathbf{\times}\mathbf{n}\mathbf{\ }\)</span><strong>positive definite
symmetric matrix</strong> <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>. The formulation of the
multi-variate Gaussian is:</p>
<div class="math notranslate nohighlight">
\[N\left( \mathbf{x;\mu,}\mathbf{\Sigma} \right) = \sqrt{\frac{1}{(2\pi)^{n}\det(\Sigma)}}e^{( - \frac{1}{2}\left( \mathbf{x} - \mathbf{\mu} \right)^{T}\Sigma^{- 1}\left( \mathbf{x} - \mathbf{\mu} \right))}\]</div>
<p>In the 2D case, <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> is a 2D
point representing the center of the Gaussian (the position of the
mode), whereas the matrix <span class="math notranslate nohighlight">\(\Sigma\)</span> influences the “shape” of the
Gaussian.</p>
<p>Examples of bivariate Gaussian distributions are shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/1f251b1c4d04abd9ad75d11b2b34c3263168f41d5ce8fa485598f7bf30f7bc9e.png" src="../_images/1f251b1c4d04abd9ad75d11b2b34c3263168f41d5ce8fa485598f7bf30f7bc9e.png" />
<img alt="../_images/3616cdd0ac2346f211bdc4356b38ff015a138159409832c1a5774354c77fa7a1.png" src="../_images/3616cdd0ac2346f211bdc4356b38ff015a138159409832c1a5774354c77fa7a1.png" />
</div>
</div>
<p>The two plots above are common representations for bivariate continuous distributions:</p>
<ul class="simple">
<li><p>The plot on the top shows a 3D representation of the PDF in which the X and Y axes are the values of the variables, while the third axis reports the probability density.</p></li>
<li><p>Since it’s often hard to draw 3D graphs, we often use a contour plot to represent the 3D curves. In the 3D plot, curves of the same color represent points which have the same density in the 3D plot.</p></li>
</ul>
<section id="effect-of-sigma">
<h4><span class="section-number">7.6.2.1. </span>Effect of <span class="math notranslate nohighlight">\(\Sigma\)</span><a class="headerlink" href="#effect-of-sigma" title="Permalink to this heading">#</a></h4>
<p>Similar to how variance affects the dispersion of a 1D Gaussian, the covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span> affects the dispersion in both axes. As a result, changing the values of the matrix will affect the shape of the distribution. Let’s consider the general covariance matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\Sigma = \begin{bmatrix}
  \sigma_x^2 &amp; \sigma_{xy} \\
  \sigma_{yx} &amp; \sigma_y^2
\end{bmatrix}
\end{split}\]</div>
<p>If the matrix is diagonal (<span class="math notranslate nohighlight">\(\sigma_{xy}=\sigma_{yx}=0\)</span>), then we have an isotropic Gaussian, meaning that it is symmetric along the two axes. Adding values different from zeros in the secondary diagonal will change the shape. Some examples are shown below:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/c405ad8432a9efe42acc83cf7d6fbe84f621d3ae27880a0196c8cbe0320eea8b.png" src="../_images/c405ad8432a9efe42acc83cf7d6fbe84f621d3ae27880a0196c8cbe0320eea8b.png" />
</div>
</div>
</section>
</section>
<section id="estimation-of-the-parameters-of-a-gaussian-distribution">
<h3><span class="section-number">7.6.3. </span>Estimation of the Parameters of a Gaussian Distribution<a class="headerlink" href="#estimation-of-the-parameters-of-a-gaussian-distribution" title="Permalink to this heading">#</a></h3>
<p>We have noted that in many cases we can assume a random variable follows
a Gaussian distribution. However, it is not yet clear how to choose the
parameters of the Gaussian distribution.</p>
<p>Given some data (remember, data is values assumed by random variables!),
we can obtain the parameters of the Gaussian distribution related to the
data with a <strong>maximum likelihood</strong> estimation.</p>
<p>This consists in computing the mean and variance parameters using the
following formula (in the univariate case):</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu = \frac{1}{n}\sum_{j}^{}x_{j}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^{2} = \frac{1}{n}\sum_{j}^{}\left( x_{j} - \mu \right)^{2}\)</span></p></li>
</ul>
<p>Where <span class="math notranslate nohighlight">\(x_{j}\)</span> represent the different data points.</p>
<p>In the multi-variate case, the computation of the multi-dimensional
<span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> vector is similar:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{\mu} = \frac{1}{n}\sum_{j}^{}\mathbf{x}_{j}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma\)</span> is instead computed as the covariance matrix related to
<span class="math notranslate nohighlight">\(X\)</span>: <span class="math notranslate nohighlight">\(\Sigma = Cov(\mathbf{X})\)</span>, i.e.,
<span class="math notranslate nohighlight">\(\Sigma_{ij} = Cov\left( \mathbf{X}_{i},\mathbf{X}_{j} \right)\)</span></p></li>
</ul>
<p>The diagram below shows an example in which we fit a Gaussian to a set of data and compare it with a 2D KDE of the data.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/407ed8c3dbc3b9d75b2781cb4de5256c8657b136c8c7f5196ef720d3bbc78fe1.png" src="../_images/407ed8c3dbc3b9d75b2781cb4de5256c8657b136c8c7f5196ef720d3bbc78fe1.png" />
</div>
</div>
</section>
<section id="central-limit-theorem">
<h3><span class="section-number">7.6.4. </span>Central Limit Theorem<a class="headerlink" href="#central-limit-theorem" title="Permalink to this heading">#</a></h3>
<p>The Central Limit Theorem is a statistical principle that states that the distribution of the sum (or average) of a large number of independent, identically distributed (i.i.d.) random variables <span class="math notranslate nohighlight">\(\{X_i\}_{i=1}^n\)</span> approaches a normal distribution as <span class="math notranslate nohighlight">\(n \to \infty\)</span>, regardless of the shape of the original population’s distribution.</p>
<p>While we will not see this theorem formally, it is a fundamental result which in some sense “justifies” the pervasive use of the Gaussian distribution in data analysis.</p>
<p>In the plot below, we plot the distributions of the average outcome of rolling a given number of dice. We can see each die as described by a different and independent random variable, hence the distribution will get close to Gaussian as we increase the number of dice.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/d3b0dcfd55343902762bdbfdf6de40e0d4d72373e1bf9592ba8247dffffb8d78.png" src="../_images/d3b0dcfd55343902762bdbfdf6de40e0d4d72373e1bf9592ba8247dffffb8d78.png" />
</div>
</div>
</section>
</section>
<section id="laplacian-distribution">
<h2><span class="section-number">7.7. </span>Laplacian Distribution<a class="headerlink" href="#laplacian-distribution" title="Permalink to this heading">#</a></h2>
<p>The Gaussian distribution assumes that the probability of an observation deviating from the mean <strong>decreases exponentially as the square of the deviation</strong>. For some types of data, this assumption is not accurate: in some cases, deviating from the mean is much more likely than prescribed by the Gaussian model. An alternative mathematical model, introduced by Laplace, posits that the probability of an observation deviating from the mean decreases exponentially with the absolute value of the deviation:</p>
<div class="math notranslate nohighlight">
\[L(x, M, b) = \frac{1}{2b} e^{-\frac{|x - M|}{b}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(M\)</span> represents the c<strong>entral/mean value of the distribution</strong>, and b is a scaling parameter known as <strong>diversity</strong>. It should be noted that due to the absolute value involved, this function is not differentiable at the mean value.</p>
<p>The <strong>best fit</strong> of this function to the data occurs when <strong>M is chosen as the median of the data</strong>, and <strong>b is chosen as the mean of the absolute differences between the data points and the median</strong>:</p>
<div class="math notranslate nohighlight">
\[M=median(\{x_i\}_{i=1}^n)\]</div>
<div class="math notranslate nohighlight">
\[b=\frac{\sum_{i=1}^n|x_i-M|}{n}\]</div>
<p>In this model, values far from the central value occur more frequently than they would in a Gaussian model. This phenomenon is referred to as <strong>fat tails</strong> in contrast to the Gaussian model, which is described as having <strong>thin tails</strong>.</p>
<p>Expectation and variance of <span class="math notranslate nohighlight">\(X \sim L\)</span> are:</p>
<div class="math notranslate nohighlight">
\[E[X] = \lambda\]</div>
<div class="math notranslate nohighlight">
\[Var(X) = \lambda\]</div>
<p>The following plot shows some examples of Laplacian distributions:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../_images/364732194241ad5e066822a4c7dc4a56aebae6f81d906fac0afbead5a714d0c2.png" src="../_images/364732194241ad5e066822a4c7dc4a56aebae6f81d906fac0afbead5a714d0c2.png" />
</div>
</div>
</section>
<section id="references">
<h2><span class="section-number">7.8. </span>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Parts of chapter 1 of [1];</p></li>
<li><p>Most of chapter 3 of [2];</p></li>
<li><p>Parts of chapter 8 of [3].</p></li>
</ul>
<p>[1] Bishop, Christopher M. <em>Pattern recognition and machine learning</em>.
springer, 2006.
<a class="reference external" href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf</a></p>
<p>[2] Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. <em>Deep
learning</em>. MIT press, 2016. <a class="reference external" href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></p>
<p>[3] Heumann, Christian, and Michael Schomaker Shalabh. Introduction to statistics and data analysis. Springer International Publishing Switzerland, 2016.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="07_probability.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Probability for Data Manipulation</p>
      </div>
    </a>
    <a class="right-next"
       href="09_information_theory.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Basic Elements of Information Theory</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-uniform-distribution">7.1. Discrete Uniform Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">7.1.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bernoulli-distribution">7.2. Bernoulli Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.2.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binomial-distribution">7.3. Binomial Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">7.3.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-distribution">7.4. Poisson Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.4.1. Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-distribution">7.5. Categorical Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-distribution">7.5.1. Multinomial Distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-distribution">7.6. Gaussian Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">7.6.1. Interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian">7.6.2. Multivariate Gaussian</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-sigma">7.6.2.1. Effect of <span class="math notranslate nohighlight">\(\Sigma\)</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-parameters-of-a-gaussian-distribution">7.6.3. Estimation of the Parameters of a Gaussian Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">7.6.4. Central Limit Theorem</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-distribution">7.7. Laplacian Distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">7.8. References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Antonino Furnari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>